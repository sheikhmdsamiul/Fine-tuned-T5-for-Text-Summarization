{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWz-Q4Sf0FGO"
      },
      "source": [
        "PIP install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5IIpcBEUQ7eQ",
        "outputId": "7794f5cd-e201-438d-8223-3b2282132286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.2.1+cu121)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->pytorch-lightning) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: xxhash, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, huggingface-hub, nvidia-cusolver-cu12, datasets, torchmetrics, pytorch-lightning\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 lightning-utilities-0.11.2 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.2.4 torchmetrics-1.4.0.post0 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install sentencepiece datasets transformers pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHRTcoP8cdS6"
      },
      "source": [
        "Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XoA-UC6FcUa4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import load_dataset\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "\n",
        "\n",
        "from transformers import T5ForConditionalGeneration, T5TokenizerFast as T5Tokenizer, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INWG9ldKRd7u"
      },
      "outputs": [],
      "source": [
        "#Getting dataset\n",
        "\n",
        "dataset = load_dataset(\"multi_news\",  split=\"train[:15000]\")\n",
        "\n",
        "df = pd.DataFrame(dataset)\n",
        "#dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVF6Bkpichg3"
      },
      "outputs": [],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSFCBniwlNgT"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Jb4hlcom9I0"
      },
      "outputs": [],
      "source": [
        "train_df, test_df = train_test_split(df, test_size = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GieyduCzyO3x"
      },
      "outputs": [],
      "source": [
        "train_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rw7faQ6kyRAh"
      },
      "outputs": [],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaBLXMyMzR5J"
      },
      "source": [
        "Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2ZUEzrTzRVS"
      },
      "outputs": [],
      "source": [
        "class NSdataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data: pd.DataFrame,\n",
        "      tokenizer: T5Tokenizer,\n",
        "      text_len: int = 512,\n",
        "      summary_len: int = 128\n",
        "      ):\n",
        "\n",
        "    self.data = data\n",
        "    self.tokenizer = tokenizer\n",
        "    self.text_len = text_len\n",
        "    self.summary_len = summary_len\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx: int):\n",
        "    data_row = self.data.iloc[idx]\n",
        "\n",
        "    text = data_row['document']\n",
        "    summary = data_row['summary']\n",
        "\n",
        "    text_encoding = tokenizer(\n",
        "        text,\n",
        "        max_length = self.text_len,\n",
        "        padding = \"max_length\",\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "    summary_encoding = tokenizer(\n",
        "        summary,\n",
        "        max_length = self.summary_len,\n",
        "        padding = \"max_length\",\n",
        "        truncation = True,\n",
        "        return_attention_mask = True,\n",
        "        add_special_tokens = True,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "    labels = summary_encoding[\"input_ids\"]\n",
        "\n",
        "    return dict(\n",
        "        text = text,\n",
        "        summary = summary,\n",
        "        text_input_ids = text_encoding[\"input_ids\"].flatten(),\n",
        "        text_attention_mask = text_encoding[\"attention_mask\"].flatten(),\n",
        "        labels = labels.flatten(),\n",
        "        labels_attention_mask = summary_encoding[\"attention_mask\"].flatten()\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xm4O5i0QLcXD"
      },
      "source": [
        "Data Module class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lylwNIT4LOTs"
      },
      "outputs": [],
      "source": [
        "class NSdataModule(pl.LightningDataModule):\n",
        "  def __init__(\n",
        "      self,\n",
        "      train_df: pd.DataFrame,\n",
        "      test_df: pd.DataFrame,\n",
        "      tokenizer: T5Tokenizer,\n",
        "      batch_size: int = 8,\n",
        "      text_len: int = 512,\n",
        "      summary_len: int = 128\n",
        "      ):\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.text_len = text_len\n",
        "    self.summary_len = summary_len\n",
        "\n",
        "  def setup(self, stage = None):\n",
        "    self.train_dataset = NSdataset(\n",
        "        self.train_df,\n",
        "        self.tokenizer,\n",
        "        self.text_len,\n",
        "        self.summary_len\n",
        "    )\n",
        "    self.test_dataset = NSdataset(\n",
        "        self.test_df,\n",
        "        self.tokenizer,\n",
        "        self.text_len,\n",
        "        self.summary_len\n",
        "    )\n",
        "\n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.train_dataset,\n",
        "        self.batch_size,\n",
        "        shuffle = True,\n",
        "        num_workers = 2\n",
        "    )\n",
        "\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.test_dataset,\n",
        "        self.batch_size,\n",
        "        shuffle = False,\n",
        "        num_workers = 2\n",
        "    )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.test_dataset,\n",
        "        self.batch_size,\n",
        "        shuffle = False,\n",
        "        num_workers = 2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwXuyHrJQNLG"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YruEJ755aeFq"
      },
      "outputs": [],
      "source": [
        "N_EPOCHS = 1\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "data_module = NSdataModule(train_df, test_df, tokenizer, batch_size= BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVYltHN1TurI"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P9RaevcQZgt"
      },
      "outputs": [],
      "source": [
        "class NSmodel(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "\n",
        "    super().__init__()\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict = True)\n",
        "\n",
        "  def forward(\n",
        "      self,\n",
        "      input_ids,\n",
        "      attention_mask,\n",
        "      decoder_attention_mask,\n",
        "      labels = None\n",
        "      ):\n",
        "    output = self.model(\n",
        "        input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        labels = labels,\n",
        "        decoder_attention_mask = decoder_attention_mask\n",
        "    )\n",
        "\n",
        "    return output.loss, output.logits\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss, outputs = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        labels = labels,\n",
        "        decoder_attention_mask = labels_attention_mask\n",
        "    )\n",
        "\n",
        "    self.log(\"train_loss\", loss, prog_bar = True, logger= True)\n",
        "    return loss\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss, outputs = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        labels = labels,\n",
        "        decoder_attention_mask = labels_attention_mask\n",
        "    )\n",
        "\n",
        "    self.log(\"val_loss\", loss, prog_bar = True, logger= True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch[\"text_input_ids\"]\n",
        "    attention_mask = batch[\"text_attention_mask\"]\n",
        "    labels = batch[\"labels\"]\n",
        "    labels_attention_mask = batch[\"labels_attention_mask\"]\n",
        "\n",
        "    loss, outputs = self(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask,\n",
        "        labels = labels,\n",
        "        decoder_attention_mask = labels_attention_mask\n",
        "    )\n",
        "\n",
        "    self.log(\"test_loss\", loss, prog_bar = True, logger= True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return AdamW(self.parameters(), lr = 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzeGk6BjUGE_"
      },
      "outputs": [],
      "source": [
        "model = NSmodel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7aTTDZCX30S"
      },
      "source": [
        "Tensor Board"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "figTkeU6Xi3-"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./lightning_logs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Usrwtke4YphS"
      },
      "outputs": [],
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath = \"checkpoints\",\n",
        "    filename = \"best-checkpoint\",\n",
        "    save_top_k = 1,\n",
        "    verbose = True,\n",
        "    monitor = \"val_loss\",\n",
        "    mode = \"min\"\n",
        ")\n",
        "\n",
        "logger = TensorBoardLogger(\"lightning_logs\", name = \"news-summary\")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    logger = logger,\n",
        "    callbacks = checkpoint_callback,\n",
        "    max_epochs = N_EPOCHS\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnZniKEdaS1R"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwpB8jWro_Li"
      },
      "outputs": [],
      "source": [
        "device=device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85LAaiV4bjbI"
      },
      "outputs": [],
      "source": [
        "trained_model= NSmodel.load_from_checkpoint(\n",
        "    trainer.checkpoint_callback.best_model_path\n",
        ")\n",
        "#trained_model=trained_model.to(device)\n",
        "trained_model.freeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYJ1n78cWTWS"
      },
      "outputs": [],
      "source": [
        "def summarize(text):\n",
        "  text_encoding = tokenizer(\n",
        "      text,\n",
        "      max_length = 512,\n",
        "      padding = \"max_length\",\n",
        "      truncation = True,\n",
        "      return_attention_mask = True,\n",
        "      add_special_tokens = True,\n",
        "      return_tensors = \"pt\"\n",
        "      ).to(device)\n",
        "\n",
        "  generated_ids = trained_model.model.generate(\n",
        "      input_ids = text_encoding[\"input_ids\"],\n",
        "      attention_mask = text_encoding[\"attention_mask\"],\n",
        "      max_length = 250,\n",
        "      num_beams = 2,\n",
        "      repetition_penalty = 2.5,\n",
        "      length_penalty = 1.0,\n",
        "      early_stopping = False\n",
        "  )\n",
        "\n",
        "  preds = [\n",
        "      tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "      for gen_id in generated_ids\n",
        "  ]\n",
        "\n",
        "  return \"\".join(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuGHsyRIZJSX"
      },
      "outputs": [],
      "source": [
        "#sample_row = test_df.iloc[1]\n",
        "#text = sample_row[\"\"\"Articles\"\"\"]\n",
        "text= \"\"\"The Importance of Environmental Conservation\n",
        "In recent years, the urgency of environmental conservation has become increasingly apparent. The planet we inhabit is facing numerous threats, including climate change, deforestation, pollution, and loss of biodiversity. As stewards of the Earth, it is our responsibility to take action to protect and preserve our environment for future generations.\n",
        "\n",
        "One of the primary reasons environmental conservation is crucial is the impact of climate change. The increase in global temperatures, driven by human activities such as burning fossil fuels and deforestation, has led to extreme weather patterns, rising sea levels, and melting polar ice caps. These changes not only threaten wildlife habitats but also human communities, particularly those in vulnerable coastal areas. By reducing greenhouse gas emissions and promoting sustainable practices, we can mitigate some of the adverse effects of climate change.\n",
        "\n",
        "Deforestation is another significant issue that underscores the need for environmental conservation. Forests play a vital role in regulating the Earth's climate, acting as carbon sinks that absorb carbon dioxide from the atmosphere. They also provide habitats for countless species and are sources of essential resources for human populations. However, large-scale logging, agricultural expansion, and urbanization have led to the destruction of vast forest areas. Protecting and restoring forests through reforestation and sustainable land-use practices are essential steps toward environmental conservation.\n",
        "\n",
        "Pollution, in its various forms, poses a severe threat to both the environment and human health. Air pollution from vehicles and industrial processes can lead to respiratory illnesses and contribute to global warming. Water pollution, caused by the discharge of harmful chemicals and plastics, contaminates our oceans, rivers, and lakes, affecting marine life and making water unsafe for human consumption. Reducing pollution requires concerted efforts at both individual and governmental levels, including the implementation of stricter regulations, promoting recycling, and developing cleaner technologies.\n",
        "\n",
        "The loss of biodiversity is another critical issue that highlights the importance of environmental conservation. The extinction of species, driven by habitat destruction, climate change, and overexploitation, disrupts ecosystems and diminishes their resilience. Biodiversity is essential for ecosystem services such as pollination, nutrient cycling, and water purification, which are crucial for human survival. Conservation efforts, such as protecting natural habitats, creating wildlife corridors, and supporting conservation organizations, can help preserve the rich diversity of life on Earth.\n",
        "\n",
        "Moreover, environmental conservation has significant socio-economic benefits. Sustainable practices, such as eco-friendly agriculture, renewable energy, and ecotourism, can create jobs and boost local economies while protecting natural resources. Investing in green infrastructure and technologies not only helps in conserving the environment but also fosters innovation and economic growth.\n",
        "\n",
        "In conclusion, the importance of environmental conservation cannot be overstated. The challenges posed by climate change, deforestation, pollution, and loss of biodiversity require immediate and sustained action. By embracing sustainable practices, supporting conservation efforts, and advocating for stronger environmental policies, we can ensure a healthier and more sustainable planet for future generations. It is a collective responsibility that we must all share, as the health of our environment directly impacts the quality of life for all living beings.\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-9iKmvwrYS_"
      },
      "outputs": [],
      "source": [
        "model_summary = summarize(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ct43Uu3SOg2o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzHrAMp8refn"
      },
      "outputs": [],
      "source": [
        "#sample_row[\"\"\"Summaries\"\"\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcJr2xL_r_JW"
      },
      "outputs": [],
      "source": [
        "model_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwSGWD3biQ6-"
      },
      "outputs": [],
      "source": [
        "!pip install rouge\n",
        "from rouge import Rouge\n",
        "ref_summary = sample_row[\"\"\"Summaries\"\"\"]\n",
        "rouge = Rouge()\n",
        "scores = rouge.get_scores(model_summary, ref_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjqxEyvOKUnh"
      },
      "outputs": [],
      "source": [
        "scores"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}